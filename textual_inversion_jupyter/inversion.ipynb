{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59ac789-46b5-4eb6-9f55-30334b498f96",
   "metadata": {},
   "source": [
    "# Textual Inversion\n",
    "\n",
    "In this workbook we will demonstrate how to fine-tune the embedding to create personalized images based on custom styles or objects. Instead of re-training the model, we can represent the custom style or object as new words in the embedding space of the model. As a result, the new word will guide the creation of new images in an intuitive way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801a0a4-aefc-4ea5-9b9b-f9dc39da2431",
   "metadata": {},
   "source": [
    "### Step 1: Download Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28e13f-a72c-4ac4-bc17-fdbd9684386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61846a-af8d-43b2-81ad-841b8feeb2d4",
   "metadata": {},
   "source": [
    "### Step 2: Training\n",
    "A full training run takes ~1 hour on one V100 GPU. For the essence of time we will not be executing the\n",
    "following bash script, but here are the contents. The model is can be foung in the huggingface\n",
    "website \"runwayml/stable-diffusion-v1-5\". And for the purposes of this textual inversion we are\n",
    "doing this for electronics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373cfe8-06ff-4803-bd6b-73ff0f352233",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23cea2-c73c-49b1-a09a-fcd3ca12e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%sh\n",
    "#chmod +x train.sh\n",
    "#./train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1666e77-7ff5-44fd-846d-1b632d8ada82",
   "metadata": {},
   "source": [
    "Once training is complete it should spit out a directory with the name that you specified in the \n",
    "previous step. For ours we set it to <b>textual_inversion_elec/</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e2c83-65ed-421d-90db-f2ff276f47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls textual_inversion_elec/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b237c6a-36c6-4ad1-ae83-9cb295890f1d",
   "metadata": {},
   "source": [
    "### Step 3: Inference\n",
    "Once you have trained a model using above command, the inference can be done simply using the StableDiffusionPipeline. Make sure to include the placeholder_token in your prompt. For ours we set our placeholder_token to be <electron>. For the model_id, you should set it to the name of the folder that got outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c31255-dbc3-447e-a962-f7e2a25e2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "    model_id = \"textual_inversion_elec\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id).to(\"cuda\")\n",
    "    pipe.safety_checker = lambda images, clip_input: (images, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d76185c-a181-44d0-834a-2c86b4b5fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A <electron> large battery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394f6d79-4ed3-463a-b281-5215d4dc232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024099111557006836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 51,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1130fca2be324bd1afed5cd756655e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5, height=256, width=256).images[0]\n",
    "\n",
    "image.save(\"battery.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b464cea1-567a-4ab3-be1f-7f8bbaba6f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"battery.png\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"battery.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55089a79-7cf8-4357-b287-4b706c07e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae0d599-d988-4020-8e56-d9e0984f7e2a",
   "metadata": {},
   "source": [
    "With the recent surge in development in AI we are looking forward to more great tools and state-of-the-art models from the open-source communities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
